
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** is the basic learning algorithm for classification problems. It is simple but elegant in its form. This notebook will cover the algorithms of Logistic Regression and build it in Python from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####We start from the binary classifications####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) let's first define the notations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***$m$*** - Number of training examples\n",
    "\n",
    "***$n$*** - Number of features\n",
    "\n",
    "***$X$*** - Features\n",
    "\n",
    "***$y$*** - Target (discrete)\n",
    "\n",
    "***$(X^{(i)}$,$y^{(i)})$*** - $i^{th}$ taining example\n",
    "\n",
    "***$\\theta: (\\theta_1,\\theta_2,...,\\theta_n)^T$*** - model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) The hypothesis of the Logistic Regression is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_\\theta(X) = g(\\theta^TX)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Where\\;\\; g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Here $g(z)$ is called the Sigmoid Function. We will use it for the activation function of neurons later in the Neural Network as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},